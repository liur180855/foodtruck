# Instructions
  a. install dependencies: make sure python3.6 is install. Other version of python3 may work. clone the current repo. run `pip install sodapy`, `pip install configparser`, `pip install requests`  
  b. build your program: N/A  
  c. run your program: `python get_food_truck_script.py` will get the first page. adding a number behind will get the page number of the result so `python get_food_truck_script.py 1` will get the next page, `python get_food_truck_script.py 2` will get page 2   
# Tech write-up
When scaling our own web application using data from Socrate, one approach we can take is to source data from Socrate daily(have a independant job that run daily to retrieve data), we can sacrafice real time consistency as food truck for the sake of scalability. However, we would have to have our own data storage our own NoSQL to host the data.
Another approach we can take is using caching, my assumption is that the granularity of the food truck operation time is 30 minutes(I.E. request coming in at 11:15 would be same as 11:20). If we cached the data coming back from Socrata every 30 minutes then we would drastically reduce idle time of our application waiting for socrata. A simple key-value cache such as redis, areospike would work. The key would be the page number of the request and the value would hold 10 records contained in json. Cache invalidation would happen at HH:00 or HH:30.
